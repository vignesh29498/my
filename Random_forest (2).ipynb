{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Content for the data_dis.csv file\n",
        "csv_content = \"\"\"value,label\n",
        "9586867657,cus_num\n",
        "A9586867657,cus_num\n",
        "E267845,country\n",
        "1345654787468,s_num\n",
        "4535,soi_id\n",
        "07865,soi_id\n",
        "1A2B3C,custom_code\n",
        "555-1234,phone_number\n",
        "\"\"\"\n",
        "\n",
        "# Specify the file path where you want to save the CSV file\n",
        "file_path = 'data_dis.csv'\n",
        "\n",
        "# Write the content to the CSV file\n",
        "with open(file_path, 'w') as f:\n",
        "    f.write(csv_content)\n",
        "\n",
        "print(f\"CSV file '{file_path}' has been successfully created with the following content:\\n\\n{csv_content}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFrUCoZiRL7B",
        "outputId": "ecccbb93-4da9-4777-c139-90c409c22681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file 'data_dis.csv' has been successfully created with the following content:\n",
            "\n",
            "value,label\n",
            "9586867657,cus_num\n",
            "A9586867657,cus_num\n",
            "E267845,country\n",
            "1345654787468,s_num\n",
            "4535,soi_id\n",
            "07865,soi_id\n",
            "1A2B3C,custom_code\n",
            "555-1234,phone_number\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ym-JoM0Q8-v",
        "outputId": "1e25a835-aee5-4534-f7da-06ada28e6ad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib"
      ],
      "metadata": {
        "id": "u7yi19ZmRC6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from CSV\n",
        "df = pd.read_csv('data_dis.csv')\n",
        "print(\"Data Loaded:\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK6oHtW3RSXY",
        "outputId": "7fda3abb-a2ff-4190-e061-c28361750f5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Loaded:\n",
            "           value         label\n",
            "0     9586867657       cus_num\n",
            "1    A9586867657       cus_num\n",
            "2        E267845       country\n",
            "3  1345654787468         s_num\n",
            "4           4535        soi_id\n",
            "5          07865        soi_id\n",
            "6         1A2B3C   custom_code\n",
            "7       555-1234  phone_number\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering: Extract length and character type features\n",
        "df['length'] = df['value'].apply(len)\n",
        "df['is_numeric'] = df['value'].apply(lambda x: x.isdigit())\n",
        "df['is_alphanumeric'] = df['value'].apply(lambda x: x.isalnum())\n",
        "df['has_hyphen'] = df['value'].apply(lambda x: '-' in x)\n",
        "print(\"\\nFeature Engineering Completed:\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMwb5AC6RTDc",
        "outputId": "a3c734df-d11c-4e97-d1db-cbd371c962c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature Engineering Completed:\n",
            "           value         label  length  is_numeric  is_alphanumeric  \\\n",
            "0     9586867657       cus_num      10        True             True   \n",
            "1    A9586867657       cus_num      11       False             True   \n",
            "2        E267845       country       7       False             True   \n",
            "3  1345654787468         s_num      13        True             True   \n",
            "4           4535        soi_id       4        True             True   \n",
            "5          07865        soi_id       5        True             True   \n",
            "6         1A2B3C   custom_code       6       False             True   \n",
            "7       555-1234  phone_number       8       False            False   \n",
            "\n",
            "   has_hyphen  \n",
            "0       False  \n",
            "1       False  \n",
            "2       False  \n",
            "3       False  \n",
            "4       False  \n",
            "5       False  \n",
            "6       False  \n",
            "7        True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "df['label_encoded'] = le.fit_transform(df['label'])\n",
        "print(\"\\nLabels Encoded:\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubMdXlgeRYkr",
        "outputId": "f0eb54c3-e44e-426c-a4c7-52b3411dc3a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Labels Encoded:\n",
            "           value         label  length  is_numeric  is_alphanumeric  \\\n",
            "0     9586867657       cus_num      10        True             True   \n",
            "1    A9586867657       cus_num      11       False             True   \n",
            "2        E267845       country       7       False             True   \n",
            "3  1345654787468         s_num      13        True             True   \n",
            "4           4535        soi_id       4        True             True   \n",
            "5          07865        soi_id       5        True             True   \n",
            "6         1A2B3C   custom_code       6       False             True   \n",
            "7       555-1234  phone_number       8       False            False   \n",
            "\n",
            "   has_hyphen  label_encoded  \n",
            "0       False              1  \n",
            "1       False              1  \n",
            "2       False              0  \n",
            "3       False              4  \n",
            "4       False              5  \n",
            "5       False              5  \n",
            "6       False              2  \n",
            "7        True              3  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features and target\n",
        "X = df[['length', 'is_numeric', 'is_alphanumeric', 'has_hyphen']]\n",
        "y = df['label_encoded']"
      ],
      "metadata": {
        "id": "kAO9vZMWRfrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"\\nData Split into Training and Testing Sets\")\n",
        "print(f\"X_train:\\n{X_train}\\nX_test:\\n{X_test}\\ny_train:\\n{y_train}\\ny_test:\\n{y_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2Kn0Kw6Rj0S",
        "outputId": "fde146b2-6272-41ea-bfc1-7b7cc04e63c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data Split into Training and Testing Sets\n",
            "X_train:\n",
            "   length  is_numeric  is_alphanumeric  has_hyphen\n",
            "0      10        True             True       False\n",
            "7       8       False            False        True\n",
            "2       7       False             True       False\n",
            "4       4        True             True       False\n",
            "3      13        True             True       False\n",
            "6       6       False             True       False\n",
            "X_test:\n",
            "   length  is_numeric  is_alphanumeric  has_hyphen\n",
            "1      11       False             True       False\n",
            "5       5        True             True       False\n",
            "y_train:\n",
            "0    1\n",
            "7    3\n",
            "2    0\n",
            "4    5\n",
            "3    4\n",
            "6    2\n",
            "Name: label_encoded, dtype: int64\n",
            "y_test:\n",
            "1    1\n",
            "5    5\n",
            "Name: label_encoded, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Evaluate Random Forest Classifier\n",
        "model_rf = RandomForestClassifier()\n",
        "model_rf.fit(X_train, y_train)\n",
        "rf_predictions = model_rf.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "print(\"\\nRandom Forest Classifier\")\n",
        "print(f\"Predictions: {rf_predictions}\")\n",
        "print(f\"Accuracy: {rf_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puf0Gop-RmKB",
        "outputId": "7cae0b33-9f75-4e92-cf0c-640093edef0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest Classifier\n",
            "Predictions: [0 5]\n",
            "Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "joblib.dump(model_rf, 'random_forest_model.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-F2dDfsSlVD",
        "outputId": "eae7c177-c478-48f2-b286-1a762edd3498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['random_forest_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for TF-IDF Vectorizer models\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['value'].astype(str))\n",
        "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "print(\"\\nTF-IDF Vectorizer Completed\")\n",
        "print(f\"X_train_tfidf:\\n{X_train_tfidf}\\nX_test_tfidf:\\n{X_test_tfidf}\")\n",
        "\n",
        "# Train and Evaluate Logistic Regression with TF-IDF\n",
        "model_lr = LogisticRegression()\n",
        "model_lr.fit(X_train_tfidf, y_train)\n",
        "lr_predictions = model_lr.predict(X_test_tfidf)\n",
        "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
        "print(\"\\nLogistic Regression with TF-IDF\")\n",
        "print(f\"Predictions: {lr_predictions}\")\n",
        "print(f\"Accuracy: {lr_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Gtau2edRp5t",
        "outputId": "ee1f3576-ea74-40a3-ef5c-0e2f384a41dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF Vectorizer Completed\n",
            "X_train_tfidf:\n",
            "  (0, 6)\t1.0\n",
            "  (1, 1)\t0.7071067811865475\n",
            "  (1, 5)\t0.7071067811865475\n",
            "  (2, 8)\t1.0\n",
            "  (3, 4)\t1.0\n",
            "  (4, 2)\t1.0\n",
            "  (5, 3)\t1.0\n",
            "X_test_tfidf:\n",
            "  (0, 7)\t1.0\n",
            "  (1, 0)\t1.0\n",
            "\n",
            "Logistic Regression with TF-IDF\n",
            "Predictions: [2 2]\n",
            "Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "joblib.dump(model_lr, 'logistic_regression_model.pkl')"
      ],
      "metadata": {
        "id": "GrbP9JJ7SiIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Evaluate SVM with TF-IDF\n",
        "model_svm = SVC()\n",
        "model_svm.fit(X_train_tfidf, y_train)\n",
        "svm_predictions = model_svm.predict(X_test_tfidf)\n",
        "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
        "print(\"\\nSupport Vector Machine with TF-IDF\")\n",
        "print(f\"Predictions: {svm_predictions}\")\n",
        "print(f\"Accuracy: {svm_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F9vF4s3RwZd",
        "outputId": "b34c4ba9-cf1a-4da3-b414-b6139a2e1204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Support Vector Machine with TF-IDF\n",
            "Predictions: [3 5]\n",
            "Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the performance\n",
        "print(\"\\nModel Comparison\")\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy}\")\n",
        "print(f\"Logistic Regression with TF-IDF Accuracy: {lr_accuracy}\")\n",
        "print(f\"Support Vector Machine with TF-IDF Accuracy: {svm_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6zL8DDXR4T0",
        "outputId": "ea79995c-f2d2-493c-afa4-3ad4abc0382f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Comparison\n",
            "Random Forest Accuracy: 0.5\n",
            "Logistic Regression with TF-IDF Accuracy: 0.0\n",
            "Support Vector Machine with TF-IDF Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "joblib.dump(model_svm, 'svm_model.pkl')"
      ],
      "metadata": {
        "id": "ZDTTyNEuSXcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Train and save Random Forest Classifier\n",
        "model_rf = RandomForestClassifier()\n",
        "model_rf.fit(X_train, y_train)\n",
        "with open('model_rf.pkl', 'wb') as f:\n",
        "    pickle.dump(model_rf, f)\n",
        "\n",
        "# Train and save Logistic Regression with TF-IDF\n",
        "model_lr = LogisticRegression()\n",
        "model_lr.fit(X_train_tfidf, y_train)\n",
        "with open('model_lr.pkl', 'wb') as f:\n",
        "    pickle.dump(model_lr, f)\n",
        "\n",
        "# Train and save SVM with TF-IDF\n",
        "model_svm = SVC()\n",
        "model_svm.fit(X_train_tfidf, y_train)\n",
        "with open('model_svm.pkl', 'wb') as f:\n",
        "    pickle.dump(model_svm, f)\n"
      ],
      "metadata": {
        "id": "7jJdnNG2Sndp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Trained Models and Prepare Data"
      ],
      "metadata": {
        "id": "NMUs04dOULeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load new data for prediction\n",
        "new_data = pd.DataFrame({\n",
        "    'value': ['123456', 'A9586867657', '1345654787468']\n",
        "})\n",
        "\n",
        "# Load models from pickle files\n",
        "with open('model_rf.pkl', 'rb') as f:\n",
        "    model_rf = pickle.load(f)\n",
        "\n",
        "with open('model_lr.pkl', 'rb') as f:\n",
        "    model_lr = pickle.load(f)\n",
        "\n",
        "with open('model_svm.pkl', 'rb') as f:\n",
        "    model_svm = pickle.load(f)\n",
        "\n",
        "# Assuming label encoder was used during training, create a LabelEncoder instance and fit it with your labels\n",
        "le = LabelEncoder()\n",
        "labels = ['cus_num', 'country', 's_num', 'soi_id', 'custom_code', 'phone_number']\n",
        "le.fit(labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "P2B91-09S4lx",
        "outputId": "e5a8b330-5c56-4c06-e536-d40ed3d780d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random fores#\n",
        "# Feature Engineering: Extract features from new data\n",
        "new_data['length'] = new_data['value'].apply(len)\n",
        "new_data['is_numeric'] = new_data['value'].apply(lambda x: x.isdigit())\n",
        "new_data['is_alphanumeric'] = new_data['value'].apply(lambda x: x.isalnum())\n",
        "new_data['has_hyphen'] = new_data['value'].apply(lambda x: '-' in x)\n",
        "\n",
        "# Prepare features for prediction\n",
        "X_new_rf = new_data[['length', 'is_numeric', 'is_alphanumeric', 'has_hyphen']]\n",
        "\n",
        "# Make predictions with Random Forest model\n",
        "rf_predictions = model_rf.predict(X_new_rf)\n",
        "predicted_labels_rf = le.inverse_transform(rf_predictions)\n",
        "\n",
        "# Output predictions\n",
        "for value, pred_rf in zip(new_data['value'], predicted_labels_rf):\n",
        "    print(f\"Value: {value}\")\n",
        "    print(f\"Random Forest Prediction: {pred_rf}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2IqHVhOS7qo",
        "outputId": "182212c5-e39f-4b77-ae9d-a7d0d6423416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value: 123456\n",
            "Random Forest Prediction: soi_id\n",
            "\n",
            "Value: A9586867657\n",
            "Random Forest Prediction: country\n",
            "\n",
            "Value: 1345654787468\n",
            "Random Forest Prediction: s_num\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example if you have TF-IDF model saved\n",
        "# Load TF-IDF Vectorizer (assuming it's already fitted)\n",
        "with open('model_lr.pkl', 'rb') as f:\n",
        "    tfidf_vectorizer = pickle.load(f)\n",
        "\n",
        "# Transform new data using fitted TF-IDF Vectorizer\n",
        "X_new_tfidf = tfidf_vectorizer.transform(new_data['value'].astype(str))\n",
        "\n",
        "# Make predictions with Logistic Regression model\n",
        "lr_predictions = model_lr.predict(X_new_tfidf)\n",
        "predicted_labels_lr = le.inverse_transform(lr_predictions)\n",
        "\n",
        "# Output predictions\n",
        "for value, pred_lr in zip(new_data['value'], predicted_labels_lr):\n",
        "    print(f\"Value: {value}\")\n",
        "    print(f\"Logistic Regression Prediction: {pred_lr}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "zEL7U8vrUcq5",
        "outputId": "4a12b5be-cdd9-4d69-aded-4623fbfa2313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'LogisticRegression' object has no attribute 'transform'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-da0d44c9e99e>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Transform new data using fitted TF-IDF Vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_new_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Make predictions with Logistic Regression model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'transform'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example if you have TF-IDF model saved\n",
        "# Transform new data using fitted TF-IDF Vectorizer\n",
        "X_new_tfidf = tfidf_vectorizer.transform(new_data['value'].astype(str))\n",
        "\n",
        "# Make predictions with SVM model\n",
        "svm_predictions = model_svm.predict(X_new_tfidf)\n",
        "predicted_labels_svm = le.inverse_transform(svm_predictions)\n",
        "\n",
        "# Output predictions\n",
        "for value, pred_svm in zip(new_data['value'], predicted_labels_svm):\n",
        "    print(f\"Value: {value}\")\n",
        "    print(f\"SVM Prediction: {pred_svm}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "pHtTxQecUdQi",
        "outputId": "d4661187-c94c-4530-9f44-f2916d70e52b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'LogisticRegression' object has no attribute 'transform'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-b2c2631ce94f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example if you have TF-IDF model saved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Transform new data using fitted TF-IDF Vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_new_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Make predictions with SVM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'transform'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load new data for prediction\n",
        "new_data = pd.DataFrame({\n",
        "    'value': ['123456', 'A9586867657', '1345654787468']\n",
        "})\n",
        "\n",
        "# Load TF-IDF Vectorizer (assuming it's already fitted during training)\n",
        "with open('model_lr.pkl', 'rb') as f:\n",
        "    tfidf_vectorizer = pickle.load(f)\n",
        "\n",
        "# Transform new data using fitted TF-IDF Vectorizer\n",
        "X_new_tfidf = tfidf_vectorizer.transform(new_data['value'].astype(str))\n",
        "\n",
        "# Load Logistic Regression model\n",
        "with open('model_lr.pkl', 'rb') as f:\n",
        "    model_lr = pickle.load(f)\n",
        "\n",
        "# Make predictions with Logistic Regression model\n",
        "lr_predictions = model_lr.predict(X_new_tfidf)\n",
        "\n",
        "# Assuming label encoder was used during training, create a LabelEncoder instance and fit it with your labels\n",
        "le = LabelEncoder()\n",
        "labels = ['cus_num', 'country', 's_num', 'soi_id', 'custom_code', 'phone_number']\n",
        "le.fit(labels)\n",
        "\n",
        "# Decode label predictions\n",
        "predicted_labels_lr = le.inverse_transform(lr_predictions)\n",
        "\n",
        "# Output predictions\n",
        "for value, pred_lr in zip(new_data['value'], predicted_labels_lr):\n",
        "    print(f\"Value: {value}\")\n",
        "    print(f\"Logistic Regression Prediction: {pred_lr}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "mra3kS4zUles",
        "outputId": "4550ecea-cddc-4ea8-8b36-15a6cef3f3c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'LogisticRegression' object has no attribute 'transform'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-fc389d2f3d86>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Transform new data using fitted TF-IDF Vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mX_new_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Load Logistic Regression model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'transform'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load CSV file\n",
        "file_path = r'/content/input.xlsx'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Assuming the CSV file has a header row and the second row contains the data for prediction\n",
        "input_data = df.iloc[1]['value']  # Assuming 'value' is the column name containing text data for prediction\n",
        "#input_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "Jz3vJpKlUwJR",
        "outputId": "7eb1240d-e627-44da-9769-2498f3459efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "'utf-8' codec can't decode byte 0x82 in position 16: invalid start byte",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-fbde61999a15>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'/content/input.xlsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Assuming the CSV file has a header row and the second row contains the data for prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1678\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1679\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1680\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Fail here loudly instead of in cython after reading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyarrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x82 in position 16: invalid start byte"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load new data for prediction\n",
        "new_data = pd.DataFrame({\n",
        "    'value': ['123456', 'A9586867658', '1234567893456']\n",
        "})\n",
        "\n",
        "# Load models from pickle files\n",
        "with open('model_rf.pkl', 'rb') as f:\n",
        "    model_rf = pickle.load(f)\n",
        "\n",
        "with open('model_lr.pkl', 'rb') as f:\n",
        "    model_lr = pickle.load(f)\n",
        "\n",
        "with open('model_svm.pkl', 'rb') as f:\n",
        "    model_svm = pickle.load(f)\n",
        "\n",
        "# Assuming label encoder was used during training, create a LabelEncoder instance and fit it with your labels\n",
        "le = LabelEncoder()\n",
        "labels = ['cus_num', 'country', 's_num', 'soi_id', 'custom_code', 'phone_number']\n",
        "le.fit(labels)\n",
        "\n",
        "\n",
        "#Random fores#\n",
        "# Feature Engineering: Extract features from new data\n",
        "new_data['length'] = new_data['value'].apply(len)\n",
        "new_data['is_numeric'] = new_data['value'].apply(lambda x: x.isdigit())\n",
        "new_data['is_alphanumeric'] = new_data['value'].apply(lambda x: x.isalnum())\n",
        "new_data['has_hyphen'] = new_data['value'].apply(lambda x: '-' in x)\n",
        "\n",
        "# Prepare features for prediction\n",
        "X_new_rf = new_data[['length', 'is_numeric', 'is_alphanumeric', 'has_hyphen']]\n",
        "\n",
        "# Make predictions with Random Forest model\n",
        "rf_predictions = model_rf.predict(X_new_rf)\n",
        "predicted_labels_rf = le.inverse_transform(rf_predictions)\n",
        "\n",
        "# Output predictions\n",
        "for value, pred_rf in zip(new_data['value'], predicted_labels_rf):\n",
        "    print(f\"Value: {value}\")\n",
        "    print(f\"Random Forest Prediction: {pred_rf}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdjIJkx2WWWu",
        "outputId": "01efc5af-ad25-4966-8213-6501eaa81df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value: 123456\n",
            "Random Forest Prediction: soi_id\n",
            "\n",
            "Value: A9586867658\n",
            "Random Forest Prediction: country\n",
            "\n",
            "Value: 1234567893456\n",
            "Random Forest Prediction: s_num\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load training data from CSV\n",
        "file_path = 'data_dis.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "print(\"Loaded Data:\")\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTNIHnYgYCHp",
        "outputId": "1e38594d-c6da-4dd8-aa7a-f5a508e5809a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Data:\n",
            "           value         label\n",
            "0     9586867657       cus_num\n",
            "1    A9586867657       cus_num\n",
            "2        E267845       country\n",
            "3  1345654787468         s_num\n",
            "4           4535        soi_id\n",
            "5          07865        soi_id\n",
            "6         1A2B3C   custom_code\n",
            "7       555-1234  phone_number\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Feature engineering using direct methods and regular expressions\n",
        "def extract_features(value):\n",
        "    # Direct method feature extraction\n",
        "    length = len(value)\n",
        "    is_numeric_dm = int(value.isdigit())\n",
        "    is_alphabetic_dm = int(value.isalpha())\n",
        "    is_alphanumeric_dm = int(value.isalnum())\n",
        "    has_hyphen_dm = int('-' in value)\n",
        "    has_letters_dm = int(any(c.isalpha() for c in value))\n",
        "    has_numbers_dm = int(any(c.isdigit() for c in value))\n",
        "    has_spaces_dm = int(any(c.isspace() for c in value))\n",
        "    has_special_chars_dm = int(bool(re.search('[^a-zA-Z0-9\\s]', value)))\n",
        "\n",
        "    # Regular expression feature extraction\n",
        "    is_numeric_re = int(bool(re.match('^\\d+$', value)))\n",
        "    is_alphabetic_re = int(bool(re.match('^[a-zA-Z]+$', value)))\n",
        "    is_alphanumeric_re = int(bool(re.match('^[a-zA-Z0-9]+$', value)))\n",
        "    has_hyphen_re = int(bool(re.search('-', value)))\n",
        "    has_letters_re = int(bool(re.search('[a-zA-Z]', value)))\n",
        "    has_numbers_re = int(bool(re.search('[0-9]', value)))\n",
        "    has_spaces_re = int(bool(re.search('\\s', value)))\n",
        "    has_special_chars_re = int(bool(re.search('[^a-zA-Z0-9\\s]', value)))\n",
        "\n",
        "    return [\n",
        "        length,\n",
        "        is_numeric_dm, is_alphabetic_dm, is_alphanumeric_dm, has_hyphen_dm, has_letters_dm, has_numbers_dm, has_spaces_dm, has_special_chars_dm,\n",
        "        is_numeric_re, is_alphabetic_re, is_alphanumeric_re, has_hyphen_re, has_letters_re, has_numbers_re, has_spaces_re, has_special_chars_re\n",
        "    ]\n",
        "\n",
        "# Apply feature extraction to the data\n",
        "features = df['value'].apply(extract_features).tolist()\n",
        "\n",
        "# Create a DataFrame for the features\n",
        "feature_columns = [\n",
        "    'length',\n",
        "    'is_numeric_dm', 'is_alphabetic_dm', 'is_alphanumeric_dm', 'has_hyphen_dm', 'has_letters_dm', 'has_numbers_dm', 'has_spaces_dm', 'has_special_chars_dm',\n",
        "    'is_numeric_re', 'is_alphabetic_re', 'is_alphanumeric_re', 'has_hyphen_re', 'has_letters_re', 'has_numbers_re', 'has_spaces_re', 'has_special_chars_re'\n",
        "]\n",
        "\n",
        "features_df = pd.DataFrame(features, columns=feature_columns)\n",
        "print(\"Extracted Features:\")\n",
        "print(features_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp37W-tKYCEQ",
        "outputId": "8f6d1281-484b-4372-809d-f40192449c0b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Features:\n",
            "   length  is_numeric_dm  is_alphabetic_dm  is_alphanumeric_dm  has_hyphen_dm  \\\n",
            "0      10              1                 0                   1              0   \n",
            "1      11              0                 0                   1              0   \n",
            "2       7              0                 0                   1              0   \n",
            "3      13              1                 0                   1              0   \n",
            "4       4              1                 0                   1              0   \n",
            "5       5              1                 0                   1              0   \n",
            "6       6              0                 0                   1              0   \n",
            "7       8              0                 0                   0              1   \n",
            "\n",
            "   has_letters_dm  has_numbers_dm  has_spaces_dm  has_special_chars_dm  \\\n",
            "0               0               1              0                     0   \n",
            "1               1               1              0                     0   \n",
            "2               1               1              0                     0   \n",
            "3               0               1              0                     0   \n",
            "4               0               1              0                     0   \n",
            "5               0               1              0                     0   \n",
            "6               1               1              0                     0   \n",
            "7               0               1              0                     1   \n",
            "\n",
            "   is_numeric_re  is_alphabetic_re  is_alphanumeric_re  has_hyphen_re  \\\n",
            "0              1                 0                   1              0   \n",
            "1              0                 0                   1              0   \n",
            "2              0                 0                   1              0   \n",
            "3              1                 0                   1              0   \n",
            "4              1                 0                   1              0   \n",
            "5              1                 0                   1              0   \n",
            "6              0                 0                   1              0   \n",
            "7              0                 0                   0              1   \n",
            "\n",
            "   has_letters_re  has_numbers_re  has_spaces_re  has_special_chars_re  \n",
            "0               0               1              0                     0  \n",
            "1               1               1              0                     0  \n",
            "2               1               1              0                     0  \n",
            "3               0               1              0                     0  \n",
            "4               0               1              0                     0  \n",
            "5               0               1              0                     0  \n",
            "6               1               1              0                     0  \n",
            "7               0               1              0                     1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(df['label'])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_df, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest model\n",
        "model_rf = RandomForestClassifier()\n",
        "model_rf.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model and label encoder to local files\n",
        "with open('model_rf.pkl', 'wb') as f:\n",
        "    pickle.dump(model_rf, f)\n",
        "\n",
        "with open('label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(le, f)\n",
        "\n",
        "print(\"Model and label encoder saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFJ_H8atX__H",
        "outputId": "a3578074-95b8-4d25-f94d-255f888b164c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and label encoder saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually provided list of data for prediction\n",
        "data_to_predict = ['654321', 'B123456789', '5678123456789', '6789', '3D4F5H', '666-7890', '490', '400']\n",
        "\n",
        "# Prepare features for prediction\n",
        "X_input = [extract_features(value) for value in data_to_predict]\n",
        "\n",
        "# Convert to DataFrame\n",
        "X_input_df = pd.DataFrame(X_input, columns=feature_columns)\n",
        "\n",
        "# Load Random Forest model\n",
        "with open('model_rf.pkl', 'rb') as f:\n",
        "    model_rf = pickle.load(f)\n",
        "\n",
        "# Load label encoder\n",
        "with open('label_encoder.pkl', 'rb') as f:\n",
        "    le = pickle.load(f)\n",
        "\n",
        "# Make predictions with Random Forest model\n",
        "rf_predictions = model_rf.predict(X_input_df)\n",
        "\n",
        "# Decode label predictions\n",
        "predicted_labels = le.inverse_transform(rf_predictions)\n",
        "\n",
        "# Print prediction results\n",
        "for value, label in zip(data_to_predict, predicted_labels):\n",
        "    print(f\"Input Data: {value} -> Prediction: {label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxdHRPWlYS-U",
        "outputId": "5d7f1de9-83d5-4d31-9265-c065daeb9e54"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Data: 654321 -> Prediction: soi_id\n",
            "Input Data: B123456789 -> Prediction: country\n",
            "Input Data: 5678123456789 -> Prediction: s_num\n",
            "Input Data: 6789 -> Prediction: soi_id\n",
            "Input Data: 3D4F5H -> Prediction: custom_code\n",
            "Input Data: 666-7890 -> Prediction: phone_number\n",
            "Input Data: 490 -> Prediction: soi_id\n",
            "Input Data: 400 -> Prediction: soi_id\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IQXzY11dYWPc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}