import pandas as pd
import glob
import os
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
import joblib  # Correct import for joblib

def load_and_merge_data(raw_folder, meaning_folder):
    raw_files = glob.glob(os.path.join(raw_folder, 'handoff_*.csv'))
    meaning_files = glob.glob(os.path.join(meaning_folder, 'icd_*.csv'))
    
    if not raw_files or not meaning_files:
        print("No files found. Please check your file paths and patterns.")
        return pd.DataFrame()  # Return an empty DataFrame
    
    raw_files.sort()
    meaning_files.sort()
    
    all_data = []
    
    for raw_file, meaning_file in zip(raw_files, meaning_files):
        raw_data = pd.read_csv(raw_file)
        meaning_data = pd.read_csv(meaning_file)
        
        # Debug: print columns of each file
        print(f"Raw file '{raw_file}' columns: {raw_data.columns}")
        print(f"Meaning file '{meaning_file}' columns: {meaning_data.columns}")
        
        # Check and correct column names if necessary
        if 'Text_ID' in raw_data.columns:
            raw_data.rename(columns={'Text_ID': 'text_id'}, inplace=True)
        if 'Text_ID_1' in raw_data.columns:
            raw_data.rename(columns={'Text_ID_1': 'Text_ID_1'}, inplace=True)
        if 'ICD_C1' in meaning_data.columns:
            meaning_data.rename(columns={'ICD_C1': 'ICD_C1'}, inplace=True)
        if 'ICD_C2' in meaning_data.columns:
            meaning_data.rename(columns={'ICD_C2': 'ICD_C2'}, inplace=True)
        
        if 'text_id' not in raw_data.columns or 'text_id' not in meaning_data.columns:
            print(f"Missing 'text_id' in {raw_file} or {meaning_file}")
            continue
        
        # Ensure all columns are strings before concatenation
        raw_data['Raw Text'] = raw_data[['text_id', 'Text_ID_1']].astype(str).agg(' '.join, axis=1)
        
        combined_data = pd.merge(raw_data[['text_id', 'Raw Text']], meaning_data[['text_id', 'ICD_C1', 'ICD_C2']], on='text_id')
        all_data.append(combined_data)
    
    if all_data:
        return pd.concat(all_data, ignore_index=True)
    else:
        return pd.DataFrame()  # Return an empty DataFrame if no data was combined

def preprocess_data(data):
    if data.empty:
        print("No data to preprocess. Exiting.")
        return None, None, None
    
    # Convert 'Raw Text' column to string
    data['Raw Text'] = data['Raw Text'].astype(str)
    
    # Combine the meanings into a single column for training
    data['Meaning'] = data[['ICD_C1', 'ICD_C2']].astype(str).agg(' '.join, axis=1)
    
    X = data['Raw Text']
    y = data['Meaning']
    
    return X, y

def train_model(X, y):
    if X is None or y is None:
        print("No data to train. Exiting.")
        return None
    
    # Build a pipeline with TF-IDF Vectorizer and Logistic Regression
    model_pipeline = Pipeline([
        ('tfidf', TfidfVectorizer()),
        ('clf', LogisticRegression(max_iter=1000))
    ])
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model_pipeline.fit(X_train, y_train)
    
    # Debug: Print model accuracy on the test set
    accuracy = model_pipeline.score(X_test, y_test)
    print(f"Model accuracy on test set: {accuracy:.2f}")
    
    # Save the trained model to a file using joblib
    model_filename = 'text_pattern_model.pkl'  # Name of the model file
    model_path = os.path.join('model', model_filename)  # Replace with your desired path
    joblib.dump(model_pipeline, model_path)
    print(f"Trained model saved to {model_path}")
    
    return model_pipeline

def predict_meanings(model, new_raw_file, output_file):
    if model is None:
        print("Model not available. Exiting.")
        return
    
    new_raw_data = pd.read_csv(new_raw_file)
    if 'Text_ID' in new_raw_data.columns:
        new_raw_data.rename(columns={'Text_ID': 'text_id'}, inplace=True)
    if 'Text_ID_1' in new_raw_data.columns:
        new_raw_data.rename(columns={'Text_ID_1': 'Text_ID_1'}, inplace=True)
    
    if 'text_id' not in new_raw_data.columns:
        print(f"New raw file is missing 'text_id' column: {new_raw_file}")
        return
    
    # Ensure all columns are strings before concatenation
    new_raw_data['Raw Text'] = new_raw_data[['text_id', 'Text_ID_1']].astype(str).agg(' '.join, axis=1)
    
    # Predict meanings using the trained model
    predicted_meanings = model.predict(new_raw_data['Raw Text'])
    
    # Add predicted meanings to the new_raw_data DataFrame
    new_raw_data['Predicted Meaning'] = predicted_meanings
    
    # Save predictions to an output file
    new_raw_data.to_csv(output_file, index=False)
    print(f"Predictions saved to {output_file}")

if __name__ == "__main__":
    raw_folder = 'path/to/handoff/files'
    meaning_folder = 'path/to/icd/files'
    new_raw_file = 'path/to/new_handoff.csv'
    output_file = 'path/to/predicted_meanings.csv'
    
    # Load and merge data
    data = load_and_merge_data(raw_folder, meaning_folder)
    
    if data.empty:
        print("No data to process. Please check your input files.")
    else:
        # Preprocess data
        X, y = preprocess_data(data)
        
        # Train model
        model = train_model(X, y)
        
        # Predict and save results from the new raw file
        predict_meanings(model, new_raw_file, output_file)
