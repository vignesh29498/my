import os
import pandas as pd

def read_csv_files(folder_path):
    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]
    dataframes = []
    for file in csv_files:
        df = pd.read_csv(os.path.join(folder_path, file))
        dataframes.append(df)
    return dataframes

def remove_duplicates(dataframes):
    unique_dfs = []
    for df in dataframes:
        unique_df = df.apply(lambda col: col.drop_duplicates().reset_index(drop=True))
        unique_dfs.append(unique_df)
    return unique_dfs

def consolidate_data(dataframes):
    consolidated_df = pd.concat(dataframes, axis=0, ignore_index=True)
    consolidated_df = consolidated_df.apply(lambda col: col.drop_duplicates().reset_index(drop=True))
    return consolidated_df

def write_final_csv(consolidated_df, output_path):
    consolidated_df.to_csv(output_path, index=False)

# Specify the folder path and output file path
folder_path = 'path_to_folder_with_csv_files'
output_path = 'path_to_final_output_file/final.csv'

# Process the CSV files
dataframes = read_csv_files(folder_path)
unique_dfs = remove_duplicates(dataframes)
consolidated_df = consolidate_data(unique_dfs)
write_final_csv(consolidated_df, output_path)
