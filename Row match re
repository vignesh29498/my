import re
import pandas as pd
from datetime import datetime
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report, accuracy_score
import joblib

# Path to the master sheet
master_sheet_path = 'master_sheet.xlsx'

# Read the master sheet into a DataFrame
master_df = pd.read_excel(master_sheet_path)

# List to store all regex patterns and corresponding labels
all_data = []

# Function to determine the type and create regex
def create_regex_pattern(value):
    # Check if it's an integer
    if value.isdigit():
        return r'\b\d+\b'
    
    # Check if it's a float
    try:
        float(value)
        return r'\b\d+\.\d+\b'
    except ValueError:
        pass
    
    # Check if it's a date
    date_patterns = [
        r'\b\d{4}-\d{2}-\d{2}\b',  # YYYY-MM-DD
        r'\b\d{2}/\d{2}/\d{4}\b',  # MM/DD/YYYY
        r'\b\d{4}/\d{2}/\d{2}\b',  # YYYY/MM/DD
        r'\b\d{2}-\d{2}-\d{4}\b',  # DD-MM-YYYY
        r'\b\d{4}\d{2}\d{2}\b',    # YYYYMMDD
        r'\b\d{2}:\d{2}:\d{2}\b'   # HH:MM:SS
    ]
    for date_pattern in date_patterns:
        try:
            datetime.strptime(value, date_pattern)
            return date_pattern
        except ValueError:
            continue
    
    # If none of the above, assume it's text
    return re.escape(value)  # Escape special characters for text

# Process each .dat file listed in the master sheet
for _, row in master_df.iterrows():
    dat_file_path = row['File Path']
    label = row['Label']
    
    # Read the .dat file
    with open(dat_file_path, 'r') as file:
        for line in file:
            line = line.strip()  # Remove leading/trailing whitespace or newline characters
            if line:
                # Convert the value to a regex pattern
                regex_pattern = create_regex_pattern(line)
                
                # Add word boundaries for text patterns
                if not regex_pattern.startswith(r'\b'):
                    regex_pattern = rf'\b{regex_pattern}\b'
                
                # Add to the list with the specified label
                all_data.append((regex_pattern, label))

# Convert the list of regex patterns and labels into a DataFrame
df = pd.DataFrame(all_data, columns=['Regular Expression', 'Label'])

# Create a mapping for labels
label_mapping = {label: chr(65 + i) for i, label in enumerate(df['Label'].unique())}

# Map the labels to alphabetic values
df['Label'] = df['Label'].map(label_mapping)

# Feature extraction using TF-IDF
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df['Regular Expression'])
y = df['Label']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train a classifier
clf = MultinomialNB()
clf.fit(X_train, y_train)

# Predict on the test set
y_pred = clf.predict(X_test)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Save the model and vectorizer
joblib.dump(clf, 'regex_classifier_model.pkl')
joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')
