import pandas as pd
import re
from datetime import datetime
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
import joblib

# Function to extract features
def extract_features(value):
    if isinstance(value, float):
        value_str = str(value)
    else:
        value_str = str(value).strip().lower()  # Lowercase and strip whitespace
    
    # Feature: Length of the value
    length = len(value_str)
    
    # Feature: Digit count
    digit_count = sum(c.isdigit() for c in value_str)
    
    # Feature: Alphabetic count
    alpha_count = sum(c.isalpha() for c in value_str)
    
    # Feature: Special characters count
    special_chars_count = len(re.findall(r'[^a-zA-Z0-9]', value_str))
    
    # Feature: Is datetime and extract datetime components if applicable
    try:
        datetime_obj = pd.to_datetime(value_str, errors='raise')
        is_datetime = 1
        year = datetime_obj.year
        month = datetime_obj.month
        day = datetime_obj.day
        hour = datetime_obj.hour
        minute = datetime_obj.minute
        second = datetime_obj.second
    except ValueError:
        is_datetime = 0
        year = month = day = hour = minute = second = -1  # Use -1 to indicate non-datetime
    
    return [length, digit_count, alpha_count, special_chars_count, is_datetime, year, month, day, hour, minute, second]

# Path to your main CSV file containing file paths in column_a
main_file_path = 'main_file.csv'

# Read the main CSV into a DataFrame
df_main = pd.read_csv(main_file_path)

# Assuming column names are 'column_a' (file paths) and 'column_b' (target)
column_a_values = df_main['column_a']
column_b_values = df_main['column_b']

# Prepare to collect all extracted features and labels
X_all = []
y_all = []

# Iterate through each file path in column_a
for file_path in column_a_values:
    # Read the CSV file specified in file_path
    try:
        df = pd.read_csv(file_path)
    except FileNotFoundError:
        print(f"File '{file_path}' not found. Skipping...")
        continue
    
    # Extract features for column_a values in this CSV
    column_a_values = df['column_a']
    features = [extract_features(value) for value in column_a_values]
    X_all.extend(features)
    
    # Append corresponding column_b values (target labels)
    y_all.extend(column_b_values[:len(features)])  # Assuming column_b has the same number of rows as column_a in each CSV

# Convert features and labels to DataFrame and array
X = pd.DataFrame(X_all, columns=['length', 'digit_count', 'alpha_count', 'special_chars_count', 
                                 'is_datetime', 'year', 'month', 'day', 'hour', 'minute', 'second'])
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y_all)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Gradient Boosting model
model = GradientBoostingClassifier(random_state=42)
model.fit(X_train, y_train)

# Evaluate the model
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Model Accuracy: {accuracy * 100:.2f}%')

# Save the model and label encoder
joblib.dump(model, 'gradient_boosting_model_with_filepaths.pkl')
joblib.dump(label_encoder, 'label_encoder_with_filepaths.pkl')
