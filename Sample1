import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re
import numpy as np
import spacy

# Load the spaCy language model
nlp = spacy.load('en_core_web_sm')

# Read the CSV file
file_path = 'your_training_data.csv'
df = pd.read_csv(file_path)

# Priority columns
priority_columns = ['Description', 'Keywords']

# Sample input sentence
input_sentence = "I need a small versatile tool for everyday use."

# Function to extract keywords
def extract_keywords(sentence):
    sentence = re.sub(r'\W+', ' ', sentence).lower()
    return sentence.split()

# Extracted keywords from input sentence
input_keywords = extract_keywords(input_sentence)

# Approach 1: Simple Keyword Matching
def simple_keyword_matching(df, input_keywords, priority_columns):
    for idx, row in df.iterrows():
        for col in priority_columns:
            text = re.sub(r'\W+', ' ', str(row[col])).lower()
            if any(keyword in text for keyword in input_keywords):
                return row['ID'], row['Name']
    return None, None

# Approach 2: TF-IDF Vectorization
def tfidf_matching(df, input_sentence, priority_columns):
    combined_texts = df[priority_columns].apply(lambda x: ' '.join(x.astype(str)), axis=1)
    vectorizer = TfidfVectorizer().fit_transform(combined_texts)
    input_vec = TfidfVectorizer().fit(combined_texts).transform([input_sentence])
    cosine_similarities = cosine_similarity(vectorizer, input_vec).flatten()
    best_match_idx = np.argmax(cosine_similarities)
    return df.iloc[best_match_idx]['ID'], df.iloc[best_match_idx]['Name']

# Approach 3: Semantic Similarity
def semantic_similarity(df, input_sentence, priority_columns):
    input_doc = nlp(input_sentence)
    best_score = -1
    best_id, best_name = None, None
    for idx, row in df.iterrows():
        for col in priority_columns:
            row_doc = nlp(str(row[col]))
            similarity_score = input_doc.similarity(row_doc)
            if similarity_score > best_score:
                best_score = similarity_score
                best_id, best_name = row['ID'], row['Name']
    return best_id, best_name

# Perform matching using all approaches
id_simple, name_simple = simple_keyword_matching(df, input_keywords, priority_columns)
id_tfidf, name_tfidf = tfidf_matching(df, input_sentence, priority_columns)
id_semantic, name_semantic = semantic_similarity(df, input_sentence, priority_columns)

# Display results
print(f"Simple Keyword Matching: Matched ID = {id_simple}, Name = {name_simple}")
print(f"TF-IDF Matching: Matched ID = {id_tfidf}, Name = {name_tfidf}")
print(f"Semantic Similarity Matching: Matched ID = {id_semantic}, Name = {name_semantic}")
