import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import NearestNeighbors

# Load the CSV report
df = pd.read_csv('report.csv')

# Specify priority columns
priority_columns = ['priority_column_1', 'priority_column_2']  # Replace with actual column names

# Combine text from all columns, giving more weight to priority columns
def combine_text(row, priority_columns, weight=2):
    text = []
    for col in df.columns:
        value = str(row[col])  # Ensure the value is a string
        if col in priority_columns:
            text.append(' '.join([value] * weight))  # Give more weight to priority columns
        else:
            text.append(value)
    return ' '.join(text)

df['combined_text'] = df.apply(combine_text, priority_columns=priority_columns, axis=1)

texts = df['combined_text'].tolist()

# Initialize TF-IDF Vectorizer
vectorizer = TfidfVectorizer(max_features=100, stop_words='english')

# Fit and transform the texts
X = vectorizer.fit_transform(texts)

# Initialize and train the Nearest Neighbors model
model = NearestNeighbors(n_neighbors=1, metric='cosine')
model.fit(X)

# Function to find the most similar row
def find_similar_row(new_sentence, model, vectorizer, priority_columns, weight=2):
    # Combine the new sentence giving more weight to priority columns
    def combine_new_text(sentence, priority_columns, weight):
        text = []
        for col in priority_columns:
            text
